{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simple AI Agent",
   "id": "9d5001da5097bc31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "\n",
    "@tool('get_weather', description='Return weather information for a given city', return_direct=False)\n",
    "def get_weather(city: str):\n",
    "    response = requests.get(f'https://wttr.in/{city}?format=j1')\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=MODEL,  # Ensure the API key of the model provider is provided in the .env \n",
    "    tools=[get_weather],\n",
    "    system_prompt='You are a helpful weather assistant, who always cracks jokes and is humorous while remaining helpful.'\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'What is the weather like in Vienna?'},\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(response)\n",
    "print(response['messages'][-1]['content'])\n"
   ],
   "id": "c21b8147bc84b68d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Standalone Model Inference",
   "id": "aba71ca2fedb47ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL,  # Ensure the API key of the model provider is provided in the .env\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "response = model.invoke('What is Python?')\n",
    "\n",
    "print(response)\n",
    "print(response.content)"
   ],
   "id": "19a75ad8c22fc61d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL,  # Ensure the API key of the model provider is provided in the .env\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "conversation = [\n",
    "    SystemMessage('You are a helpful assistant for questions regarding programming'),\n",
    "    HumanMessage('What is Python?'),\n",
    "    AIMessage('Python is an interpreted programming language.'),\n",
    "    HumanMessage('When was it released?')\n",
    "]\n",
    "\n",
    "response = model.invoke(conversation)\n",
    "\n",
    "print(response)\n",
    "print(response.content)"
   ],
   "id": "19d1619c717048b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"mistral-medium-2508\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL,  # Ensure the API key of the model provider is provided in the .env\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "for chunk in model.stream('Hello, what is Python?'):\n",
    "    print(chunk.text, end='', flush=True)\n"
   ],
   "id": "c562a16d43e2bb85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Advanced Agent Example",
   "id": "a7b1dcc71561124e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from dataclasses import dataclass\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    summary: str\n",
    "    temperature_celsius: float\n",
    "    temperature_fahrenheit: float\n",
    "    humidity: float\n",
    "\n",
    "\n",
    "@tool('get_weather', description='Return weather information for a given city', return_direct=False)\n",
    "def get_weather(city: str):\n",
    "    response = requests.get(f'https://wttr.in/{city}?format=j1')\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "@tool('locate_user', description=\"Look up a user's city based on the context\")\n",
    "def locate_user(runtime: ToolRuntime[Context]):\n",
    "    match runtime.context.user_id:\n",
    "        case 'ABC123':\n",
    "            return 'Vienna'\n",
    "        case 'XYZ456':\n",
    "            return 'London'\n",
    "        case 'HJK789':\n",
    "            return 'Paris'\n",
    "        case _:\n",
    "            return 'Unknown'\n",
    "\n",
    "\n",
    "model = init_chat_model(\n",
    "    MODEL,  # Ensure the API key of the model provider is provided in the .env\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, locate_user],\n",
    "    system_prompt='You are a helpful weather assistant, who always cracks jokes and is humorous while remaining helpful.',\n",
    "    context_schema=Context,\n",
    "    response_format=ResponseFormat,\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}}\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'What is the weather like in Vienna?'}\n",
    "    ]},\n",
    "    config=config,\n",
    "    context=Context(user_id='ABC123')\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "print(response['structured_response'].summary)\n",
    "print(response['structured_response'].temperature_celsius)\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'What is the weather like in Vienna?'}\n",
    "    ]},\n",
    "    config=config,  # Still the same thread\n",
    "    context=Context(user_id='ABC123')\n",
    ")\n",
    "\n",
    "print(response['structured_response'].summary)\n"
   ],
   "id": "cee6c8e3ae358e1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multimodal Input",
   "id": "be2faea3d16a2542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage\n",
    "from base64 import b64encode\n",
    "\n",
    "load_dotenv()\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "model = init_chat_model(MODEL)\n",
    "\n",
    "message = {\n",
    "    'role': 'user',\n",
    "    'content': [\n",
    "        {'type': 'text', 'text': 'Describe the contents of this image.'},\n",
    "        # {'type': 'image', 'url': '<YOUR_IMAGE_URL>'},\n",
    "        {\n",
    "            'type': 'image',\n",
    "            'base64': b64encode(open('image.png', 'rb').read()).decode(),\n",
    "            'mime-type': 'image/png'\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# message = HumanMessage(\n",
    "#     content=[\n",
    "#         {'type': 'text', 'text': 'Describe the contents of this image.'},\n",
    "#         # {'type': 'image', 'url': '<YOUR_IMAGE_URL>'},\n",
    "#         {\n",
    "#             'type': 'image',\n",
    "#             'base64': b64encode(open('image.png', 'rb').read()).decode(),\n",
    "#             'mime-type': 'image/png'\n",
    "#         },\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "response = model.invoke([message])\n",
    "\n",
    "print(response.content)"
   ],
   "id": "8b3bfe99b40eb545",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG Example",
   "id": "7ed7c9ef448d3002"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T10:30:58.785712Z",
     "start_time": "2025-11-14T10:30:57.725822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "MODEL = \"llama2\"\n",
    "EMBEDDING_MODEL = \"mxbai-embed-large\"\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "texts = [\n",
    "    'Apple makes very good computers.',\n",
    "    'I believe Apple is innovative!',\n",
    "    'I love apples.',\n",
    "    'I am a fan of MacBooks.',\n",
    "    'I enjoy oranges.',\n",
    "    'I like Lenovo Thinkpads.',\n",
    "    'I think pears taste very good.'\n",
    "]\n",
    "\n",
    "vector_store = FAISS.from_texts(texts=texts, embedding=embeddings)\n",
    "\n",
    "print('Similarity search results based on provided text input:')\n",
    "for text in vector_store.similarity_search('Apples are my fav food.', k=7):\n",
    "    print(text.page_content)\n",
    "print('-' * 40)\n",
    "for text in vector_store.similarity_search('Linux is the best OS!', k=7):\n",
    "    print(text.page_content)\n",
    "print('-' * 40)"
   ],
   "id": "b267b8c22d4531ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search results based on provided text input:\n",
      "I love apples.\n",
      "I enjoy oranges.\n",
      "I am a fan of MacBooks.\n",
      "I think pears taste very good.\n",
      "I believe Apple is innovative!\n",
      "Apple makes very good computers.\n",
      "I like Lenovo Thinkpads.\n",
      "----------------------------------------\n",
      "Apple makes very good computers.\n",
      "I am a fan of MacBooks.\n",
      "I like Lenovo Thinkpads.\n",
      "I believe Apple is innovative!\n",
      "I love apples.\n",
      "I enjoy oranges.\n",
      "I think pears taste very good.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T10:33:40.757919Z",
     "start_time": "2025-11-14T10:31:02.545969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.embeddings import init_embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "\n",
    "MODEL_PROVIDER = \"ollama\"\n",
    "MODEL_NAME = \"qwen3-vl:4b\"\n",
    "EMBEDDING_MODEL_NAME = \"mxbai-embed-large\"\n",
    "\n",
    "embeddings = init_embeddings(\n",
    "    model=EMBEDDING_MODEL_NAME,\n",
    "    provider=MODEL_PROVIDER\n",
    ")\n",
    "\n",
    "texts = [\n",
    "    'I love apples.',\n",
    "    'I enjoy oranges.',\n",
    "    'I think pears taste very good.',\n",
    "    'I hate bananas.',\n",
    "    'I dislike raspberries.',\n",
    "    'I despise mangos',\n",
    "    'i love Linux.',\n",
    "    'I hate Windows.'\n",
    "]\n",
    "\n",
    "vector_store = FAISS.from_texts(texts=texts, embedding=embeddings)\n",
    "\n",
    "print('Similarity search results based on provided text input:')\n",
    "for text in vector_store.similarity_search('What fruits does the person like?', k=3):\n",
    "    print(text.page_content)\n",
    "print('-' * 40)\n",
    "for text in vector_store.similarity_search('What fruits does the person hate?', k=3):\n",
    "    print(text.page_content)\n",
    "print('-' * 40)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name='kb_search',\n",
    "    description='Search the small product / fruit database for information.'\n",
    ")\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    model_provider=MODEL_PROVIDER,\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[retriever_tool],\n",
    "    system_prompt=(\n",
    "        \"You are a helpful assistant. For any questions first call the kb_search tool \"\n",
    "        \"to retrieve context, then answer succinctly. Maybe you have to use it multiple times before answering.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"message\": [{\"role\": \"user\",\n",
    "                 \"content\": \"What three fruits does the person like and what three fruits does the person like dislike?\"}]\n",
    "})\n",
    "\n",
    "print(result)\n",
    "print(\"-\" * 40)\n",
    "print(result['messages'][-1].content)"
   ],
   "id": "cc1a77b3beed0e3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search results based on provided text input:\n",
      "I enjoy oranges.\n",
      "I love apples.\n",
      "I think pears taste very good.\n",
      "----------------------------------------\n",
      "I despise mangos\n",
      "I dislike raspberries.\n",
      "I hate bananas.\n",
      "----------------------------------------\n",
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3-vl:4b', 'created_at': '2025-11-14T10:32:11.612165Z', 'done': True, 'done_reason': 'stop', 'total_duration': 68810651334, 'load_duration': 69427709, 'prompt_eval_count': 193, 'prompt_eval_duration': 1611791541, 'eval_count': 2563, 'eval_duration': 66715759615, 'model_name': 'qwen3-vl:4b', 'model_provider': 'ollama'}, id='lc_run--e50b5666-533b-46ee-bead-91259a02642c-0', tool_calls=[{'name': 'kb_search', 'args': {'query': 'small fruit'}, 'id': 'daaaad31-46d5-4089-a5bc-849cef0e0997', 'type': 'tool_call'}], usage_metadata={'input_tokens': 193, 'output_tokens': 2563, 'total_tokens': 2756}), ToolMessage(content='I love apples.\\n\\nI enjoy oranges.\\n\\nI think pears taste very good.', name='kb_search', id='eb8714d0-1a01-49d2-b58a-120827c98f81', tool_call_id='daaaad31-46d5-4089-a5bc-849cef0e0997'), AIMessage(content='Small fruits include apples, oranges, and pears.', additional_kwargs={}, response_metadata={'model': 'qwen3-vl:4b', 'created_at': '2025-11-14T10:33:40.738998Z', 'done': True, 'done_reason': 'stop', 'total_duration': 88827049917, 'load_duration': 61344250, 'prompt_eval_count': 242, 'prompt_eval_duration': 145702958, 'eval_count': 3190, 'eval_duration': 88055748692, 'model_name': 'qwen3-vl:4b', 'model_provider': 'ollama'}, id='lc_run--d06cbcfe-88f6-433a-bbac-0edcfa41ddc7-0', usage_metadata={'input_tokens': 242, 'output_tokens': 3190, 'total_tokens': 3432})]}\n",
      "----------------------------------------\n",
      "Small fruits include apples, oranges, and pears.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dynamic System Prompts",
   "id": "da28cbd77290688c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T10:34:16.582785Z",
     "start_time": "2025-11-14T10:33:51.772791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ModelRequest, dynamic_prompt\n",
    "\n",
    "PROVIDER_NAME = 'ollama'\n",
    "MODEL_NAME = 'llama2'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_role: str\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    user_role = request.runtime.context.user_role\n",
    "\n",
    "    base_prompt = 'You are a helpful and very concise assistant.'\n",
    "\n",
    "    match user_role:\n",
    "        case 'expert':\n",
    "            return f'{base_prompt} Provide detail technical responses.'\n",
    "        case 'beginner':\n",
    "            return f'{base_prompt} Keep your explanations simple and basic.'\n",
    "        case 'child':\n",
    "            return f'{base_prompt} Explain everything as if you were literally talking to a five-year old.'\n",
    "        case _:\n",
    "            return base_prompt\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=f'{PROVIDER_NAME}:{MODEL_NAME}',\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "response = agent.invoke({'messages': [{'role': 'user', 'content': 'Explain PCA.'}]},\n",
    "                        context=Context(user_role='expert'))\n",
    "\n",
    "print(response)\n",
    "print(\"-\" * 40)\n",
    "print(response['messages'][-1].content)"
   ],
   "id": "8758899d20c10d7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Explain PCA.', additional_kwargs={}, response_metadata={}, id='49b5f273-a339-4ef9-92c9-e36da53a08e8'), AIMessage(content=\"\\nPrincipal Component Analysis (PCA) is a dimension reduction technique that transforms a set of correlated variables into a set of linearly uncorrelated ones, called principal components. The goal of PCA is to find a lower-dimensional representation of the data that preserves as much information as possible about the original data.\\n\\nHere's how PCA works:\\n\\n1. Standardize the Data: The input data is standardized by subtracting the mean and dividing by the standard deviation for each variable. This ensures that all variables are on the same scale, which is important for linear transformations.\\n2. Covariance Matrix Calculation: The covariance matrix is calculated from the standardized data. The covariance matrix is a square matrix that contains the pairwise covariances between all possible combinations of variables.\\n3. Eigenvalue and Eigenvector Calculation: The eigenvectors and eigenvalues are calculated from the covariance matrix using matrix inversion. The eigenvectors represent the directions in which the principal components lie, while the eigenvalues represent the amount of variance explained by each component.\\n4. Component Selection: The eigenvectors with the largest eigenvalues are selected as the principal components. These components explain the most variance in the data and are used to create a lower-dimensional representation.\\n5. Transformation: The original data is transformed onto the new coordinate system defined by the principal components. This transformation is done by projecting each data point onto the linear combination of the principal components that explains the most variance.\\n6. Reconstruction: The original data can be reconstructed from the transformed data using the principal components. This is done by taking the linear combination of the principal components that explains the most variance in the transformed data.\\n\\nThe advantages of PCA include:\\n\\n1. Simplifies complex data sets: By reducing the number of variables, PCA can help to simplify complex data sets and make them easier to analyze.\\n2. Identifies underlying patterns: PCA can identify underlying patterns in the data that may not be immediately apparent from the original variables.\\n3. Improves model performance: By transforming the data into a lower-dimensional space, PCA can improve the performance of machine learning models by reducing overfitting and improving generalization.\\n4. Enhances visualization: PCA can enhance visualization by reducing the number of variables in a plot while preserving the most important information.\\n\\nSome common use cases for PCA include:\\n\\n1. Image compression: PCA can be used to compress images by retaining only the most important features and discarding the less important ones.\\n2. Financial portfolio analysis: PCA can be used to identify underlying patterns in financial data and reduce the dimensionality of the portfolio for easier analysis and optimization.\\n3. Gene expression analysis: PCA can be used to identify genes that are co-expressed across different samples, which can reveal important biological processes or functions.\\n4. Customer segmentation: PCA can be used to identify customer segments based on their characteristics, such as demographics and purchasing behavior.\", additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-11-14T10:34:16.575957Z', 'done': True, 'done_reason': 'stop', 'total_duration': 24774037000, 'load_duration': 2384915042, 'prompt_eval_count': 40, 'prompt_eval_duration': 285020459, 'eval_count': 660, 'eval_duration': 21325591000, 'model_name': 'llama2', 'model_provider': 'ollama'}, id='lc_run--c8ec9a8e-6716-4df0-bf1b-65966430580b-0', usage_metadata={'input_tokens': 40, 'output_tokens': 660, 'total_tokens': 700})]}\n",
      "----------------------------------------\n",
      "\n",
      "Principal Component Analysis (PCA) is a dimension reduction technique that transforms a set of correlated variables into a set of linearly uncorrelated ones, called principal components. The goal of PCA is to find a lower-dimensional representation of the data that preserves as much information as possible about the original data.\n",
      "\n",
      "Here's how PCA works:\n",
      "\n",
      "1. Standardize the Data: The input data is standardized by subtracting the mean and dividing by the standard deviation for each variable. This ensures that all variables are on the same scale, which is important for linear transformations.\n",
      "2. Covariance Matrix Calculation: The covariance matrix is calculated from the standardized data. The covariance matrix is a square matrix that contains the pairwise covariances between all possible combinations of variables.\n",
      "3. Eigenvalue and Eigenvector Calculation: The eigenvectors and eigenvalues are calculated from the covariance matrix using matrix inversion. The eigenvectors represent the directions in which the principal components lie, while the eigenvalues represent the amount of variance explained by each component.\n",
      "4. Component Selection: The eigenvectors with the largest eigenvalues are selected as the principal components. These components explain the most variance in the data and are used to create a lower-dimensional representation.\n",
      "5. Transformation: The original data is transformed onto the new coordinate system defined by the principal components. This transformation is done by projecting each data point onto the linear combination of the principal components that explains the most variance.\n",
      "6. Reconstruction: The original data can be reconstructed from the transformed data using the principal components. This is done by taking the linear combination of the principal components that explains the most variance in the transformed data.\n",
      "\n",
      "The advantages of PCA include:\n",
      "\n",
      "1. Simplifies complex data sets: By reducing the number of variables, PCA can help to simplify complex data sets and make them easier to analyze.\n",
      "2. Identifies underlying patterns: PCA can identify underlying patterns in the data that may not be immediately apparent from the original variables.\n",
      "3. Improves model performance: By transforming the data into a lower-dimensional space, PCA can improve the performance of machine learning models by reducing overfitting and improving generalization.\n",
      "4. Enhances visualization: PCA can enhance visualization by reducing the number of variables in a plot while preserving the most important information.\n",
      "\n",
      "Some common use cases for PCA include:\n",
      "\n",
      "1. Image compression: PCA can be used to compress images by retaining only the most important features and discarding the less important ones.\n",
      "2. Financial portfolio analysis: PCA can be used to identify underlying patterns in financial data and reduce the dimensionality of the portfolio for easier analysis and optimization.\n",
      "3. Gene expression analysis: PCA can be used to identify genes that are co-expressed across different samples, which can reveal important biological processes or functions.\n",
      "4. Customer segmentation: PCA can be used to identify customer segments based on their characteristics, such as demographics and purchasing behavior.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dynamic Model Choice",
   "id": "a2d444bb88042728"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T10:35:49.571697Z",
     "start_time": "2025-11-14T10:35:48.821102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents.middleware import ModelRequest, ModelResponse, wrap_model_call\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "basic_model = init_chat_model(\n",
    "    model='llama2',\n",
    "    model_provider='ollama'\n",
    ")\n",
    "advanced_model = init_chat_model(\n",
    "    model='gpt-4.1-mini',\n",
    "    model_provider='openai'\n",
    ")\n",
    "\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    message_count = len(request.state['messages'])\n",
    "\n",
    "    if message_count > 3:\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    request.model = model\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[dynamic_model_selection]\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        SystemMessage('You are a helpful and very concise assistant.'),\n",
    "        HumanMessage('What is 1+1?')\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(response['messages'][-1].content)\n",
    "print(response['messages'][-1].response_metadata['model_name'])"
   ],
   "id": "479472f43e202603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! The answer to 1+1 is 2.\n",
      "llama2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Custom Agent Middleware",
   "id": "597c5c2ca29b1979"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T10:37:10.999817Z",
     "start_time": "2025-11-14T10:36:46.534877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_PROVIDER = 'ollama'\n",
    "MODEL_NAME = 'llama2'\n",
    "\n",
    "\n",
    "class HooksDemo(AgentMiddleware):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.start_time = 0.0\n",
    "\n",
    "    def before_agent(self, state: AgentState, runtime):\n",
    "        self.start_time = time.time()\n",
    "        print('before_agent triggered')\n",
    "\n",
    "    def before_model(self, state: AgentState, runtime):\n",
    "        print('before_model triggered')\n",
    "\n",
    "    def after_model(self, state: AgentState, runtime):\n",
    "        print('after_model triggered')\n",
    "\n",
    "    def after_agent(self, state: AgentState, runtime):\n",
    "        print('after_agent:', '{:.2f}'.format(time.time() - self.start_time), 'seconds')\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=f'{PROVIDER_NAME}:{MODEL_NAME}',\n",
    "    middleware=[HooksDemo()]\n",
    ")\n",
    "\n",
    "response = agent.invoke({'messages': [{'role': 'user', 'content': 'Explain PCA.'}]},\n",
    "                        context=Context(user_role='expert'))\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(response)\n",
    "print(\"-\" * 40)\n",
    "print(response['messages'][-1].content)"
   ],
   "id": "3917b3b891ecd85a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before_agent triggered\n",
      "before_model triggered\n",
      "after_model triggered\n",
      "after_agent: 24.44 seconds\n",
      "----------------------------------------\n",
      "{'messages': [HumanMessage(content='Explain PCA.', additional_kwargs={}, response_metadata={}, id='0a1b3b62-0d70-4a36-85a8-acf63ed8306c'), AIMessage(content='Principal Component Analysis (PCA) is a dimension reduction technique that is used to simplify complex datasets by reducing the number of features or variables while retaining most of the information in the data. It is a statistical method that transforms a set of correlated variables into a set of uncorrelated variables, called principal components, which are linear combinations of the original variables.\\n\\nThe goal of PCA is to identify the underlying structure of the data and reduce the number of features while retaining as much information as possible. It is commonly used in data analysis, machine learning, and signal processing.\\n\\nPCA works by finding the directions of maximum variance in the data and projecting the data onto those directions. The resulting principal components are ordered such that the first component explains the most variation in the data, the second component explains the second most variation, and so on. The principal components are orthogonal to each other, meaning that they are not correlated.\\n\\nThe steps involved in PCA are:\\n\\n1. Data standardization: The data is standardized by subtracting the mean and dividing by the standard deviation for each variable.\\n2. Covariance matrix calculation: The covariance matrix is calculated from the standardized data.\\n3. Eigenvalue and eigenvector calculation: The eigenvalues and eigenvectors are calculated from the covariance matrix.\\n4. Component selection: The principal components are selected based on their eigenvalues, with the first component explaining the most variation in the data.\\n5. Transformation: The original data is transformed onto the new coordinate system defined by the principal components.\\n\\nPCA has many applications in data analysis, including:\\n\\n1. Data visualization: PCA can be used to reduce the number of features in a dataset and create a lower-dimensional visual representation of the data.\\n2. Feature selection: PCA can be used to identify the most important features in a dataset.\\n3. Data compression: PCA can be used to reduce the size of a dataset while retaining most of the information.\\n4. Anomaly detection: PCA can be used to detect outliers and anomalies in a dataset.\\n5. Data transformation: PCA can be used to transform data into a new coordinate system that is more conducive to machine learning algorithms.\\n6. Image compression: PCA can be used to compress images by reducing the number of features while retaining most of the information.\\n7. Text analysis: PCA can be used to reduce the dimensionality of text data and identify patterns and themes in the data.\\n8. Bioinformatics: PCA can be used to analyze gene expression data and identify patterns of gene expression that are associated with specific diseases or conditions.\\n9. Recommender systems: PCA can be used to reduce the dimensionality of user-item interaction data and identify patterns of preference that can be used to make personalized recommendations.\\n10. Time series analysis: PCA can be used to reduce the dimensionality of time series data and identify patterns and trends in the data.\\n\\nIn summary, PCA is a powerful tool for reducing the dimensionality of complex datasets while retaining most of the information in the data. It can be used for a wide range of applications, including data visualization, feature selection, data compression, anomaly detection, data transformation, image compression, text analysis, bioinformatics, recommender systems, and time series analysis.', additional_kwargs={}, response_metadata={'model': 'llama2', 'created_at': '2025-11-14T10:37:10.992362Z', 'done': True, 'done_reason': 'stop', 'total_duration': 24435499167, 'load_duration': 32042709, 'prompt_eval_count': 25, 'prompt_eval_duration': 91560708, 'eval_count': 724, 'eval_duration': 23458216791, 'model_name': 'llama2', 'model_provider': 'ollama'}, id='lc_run--04baff51-c60c-408f-a77a-a7759adeb789-0', usage_metadata={'input_tokens': 25, 'output_tokens': 724, 'total_tokens': 749})]}\n",
      "----------------------------------------\n",
      "Principal Component Analysis (PCA) is a dimension reduction technique that is used to simplify complex datasets by reducing the number of features or variables while retaining most of the information in the data. It is a statistical method that transforms a set of correlated variables into a set of uncorrelated variables, called principal components, which are linear combinations of the original variables.\n",
      "\n",
      "The goal of PCA is to identify the underlying structure of the data and reduce the number of features while retaining as much information as possible. It is commonly used in data analysis, machine learning, and signal processing.\n",
      "\n",
      "PCA works by finding the directions of maximum variance in the data and projecting the data onto those directions. The resulting principal components are ordered such that the first component explains the most variation in the data, the second component explains the second most variation, and so on. The principal components are orthogonal to each other, meaning that they are not correlated.\n",
      "\n",
      "The steps involved in PCA are:\n",
      "\n",
      "1. Data standardization: The data is standardized by subtracting the mean and dividing by the standard deviation for each variable.\n",
      "2. Covariance matrix calculation: The covariance matrix is calculated from the standardized data.\n",
      "3. Eigenvalue and eigenvector calculation: The eigenvalues and eigenvectors are calculated from the covariance matrix.\n",
      "4. Component selection: The principal components are selected based on their eigenvalues, with the first component explaining the most variation in the data.\n",
      "5. Transformation: The original data is transformed onto the new coordinate system defined by the principal components.\n",
      "\n",
      "PCA has many applications in data analysis, including:\n",
      "\n",
      "1. Data visualization: PCA can be used to reduce the number of features in a dataset and create a lower-dimensional visual representation of the data.\n",
      "2. Feature selection: PCA can be used to identify the most important features in a dataset.\n",
      "3. Data compression: PCA can be used to reduce the size of a dataset while retaining most of the information.\n",
      "4. Anomaly detection: PCA can be used to detect outliers and anomalies in a dataset.\n",
      "5. Data transformation: PCA can be used to transform data into a new coordinate system that is more conducive to machine learning algorithms.\n",
      "6. Image compression: PCA can be used to compress images by reducing the number of features while retaining most of the information.\n",
      "7. Text analysis: PCA can be used to reduce the dimensionality of text data and identify patterns and themes in the data.\n",
      "8. Bioinformatics: PCA can be used to analyze gene expression data and identify patterns of gene expression that are associated with specific diseases or conditions.\n",
      "9. Recommender systems: PCA can be used to reduce the dimensionality of user-item interaction data and identify patterns of preference that can be used to make personalized recommendations.\n",
      "10. Time series analysis: PCA can be used to reduce the dimensionality of time series data and identify patterns and trends in the data.\n",
      "\n",
      "In summary, PCA is a powerful tool for reducing the dimensionality of complex datasets while retaining most of the information in the data. It can be used for a wide range of applications, including data visualization, feature selection, data compression, anomaly detection, data transformation, image compression, text analysis, bioinformatics, recommender systems, and time series analysis.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
