{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "['A1', 'A2', 'A3']\n",
      "\n",
      "Raw dataset:\n",
      "['5', '12', '35']\n",
      "['6', '15', '36']\n",
      "['3', '16', '31']\n",
      "['4', '18', '34']\n",
      "['8', '17', '30']\n",
      "['25', '6', '14']\n",
      "['23', '8', '16']\n",
      "['26', '7', '12']\n",
      "['28', '4', '11']\n",
      "['24', '5', '18']\n",
      "\n",
      "Processed dataset:\n",
      "[5, 12, 35]\n",
      "[6, 15, 36]\n",
      "[3, 16, 31]\n",
      "[4, 18, 34]\n",
      "[8, 17, 30]\n",
      "[25, 6, 14]\n",
      "[23, 8, 16]\n",
      "[26, 7, 12]\n",
      "[28, 4, 11]\n",
      "[24, 5, 18]\n",
      "\n",
      "Centroids:\n",
      "(1, [26, 7, 12])\n",
      "(2, [24, 5, 18])\n",
      "\n",
      "Group changes:\n",
      "[False, False, False, False, False, False, False, False, False, False]\n",
      "\n",
      "Group averages:\n",
      "Group:\t1\tColumn:\t0\tMeans:\t{'sum': 205, 'total': 8, 'avg': 25.625}\n",
      "Group:\t1\tColumn:\t1\tMeans:\t{'sum': 47, 'total': 8, 'avg': 5.875}\n",
      "Group:\t1\tColumn:\t2\tMeans:\t{'sum': 108, 'total': 8, 'avg': 13.5}\n",
      "Group:\t2\tColumn:\t0\tMeans:\t{'sum': 99, 'total': 12, 'avg': 8.25}\n",
      "Group:\t2\tColumn:\t1\tMeans:\t{'sum': 169, 'total': 12, 'avg': 14.083333333333334}\n",
      "Group:\t2\tColumn:\t2\tMeans:\t{'sum': 366, 'total': 12, 'avg': 30.5}\n",
      "\n",
      "Distance changes:\n",
      "[0, 2, 2, 2]\n",
      "[0, 2, 2, 2]\n",
      "[0, 2, 2, 2]\n",
      "[0, 2, 2, 2]\n",
      "[0, 2, 2, 2]\n",
      "[0, 1, 1, 1]\n",
      "[0, 2, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 2, 1, 1]\n",
      "\n",
      "Dataset after clustering:\n",
      "[5, 12, 35, 2]\n",
      "[6, 15, 36, 2]\n",
      "[3, 16, 31, 2]\n",
      "[4, 18, 34, 2]\n",
      "[8, 17, 30, 2]\n",
      "[25, 6, 14, 1]\n",
      "[23, 8, 16, 1]\n",
      "[26, 7, 12, 1]\n",
      "[28, 4, 11, 1]\n",
      "[24, 5, 18, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Means Clustering Algorithm\n",
    "\n",
    "# ! Caution: Assumed that the dataset has no missing value,\n",
    "# !          and consists of numeric values only.\n",
    "\n",
    "# ? How the algorithm works ?\n",
    "# 1. select cluster number \"k\"\n",
    "# 2. choose randomly k centroids\n",
    "# 3. calculate distance of objects to centroids\n",
    "# 4. group based on minimum distance\n",
    "# 5. if no group update, end\n",
    "#    else, go to step 3\n",
    "\n",
    "import math\n",
    "from random import random\n",
    "\n",
    "# Determine the number of clusters arbitrarily\n",
    "k = 2\n",
    "\n",
    "# Initialize list for the processed dataset\n",
    "processed_dataset = []\n",
    "\n",
    "# Initialize list for the clustered dataset\n",
    "clustered_dataset = []\n",
    "\n",
    "# Initialize list for the raw dataset\n",
    "raw_dataset = []\n",
    "\n",
    "# Initialize list for the labels of dataset\n",
    "labels = []\n",
    "\n",
    "# Initialize dictionary for the centroids\n",
    "# Key: index of centroid (1 for k1, 2 for k2, ...)\n",
    "# Value: list of the mean data\n",
    "centroids = dict()\n",
    "\n",
    "# Initialize dictionary for column-group based average calculation \n",
    "# Key: index of centroid (1 for k1, 2 for k2, ...)\n",
    "# Value: dictionary\n",
    "#        index of attribute (column index): dictionary with 'sum', 'total', and 'avg' keys\n",
    "group_averages = dict()\n",
    "\n",
    "# Initialize list for control flow\n",
    "# If any group change occurs, list will contain at least one True value\n",
    "group_changes = [True]\n",
    "\n",
    "# Initialize list for distance changes (as list) of each sample (row)\n",
    "# distance[2]: distance changes of sample index 2 (3rd row) --> [1,1,2,2,2]\n",
    "distance_changes = []\n",
    "\n",
    "# Determine the file path of dataset\n",
    "file_path = '../Custom Datasets/k-means-test.csv'\n",
    "\n",
    "# Read all lines of the file\n",
    "with open(file_path, 'r') as file:\n",
    "  lines = file.readlines()\n",
    "\n",
    "# Get the line where the labels reside\n",
    "for line_number in range(0, len(lines)):\n",
    "    if not lines[line_number].isspace():\n",
    "        # Store the labels\n",
    "        labels = lines.pop(line_number).strip().split(',')\n",
    "        break\n",
    "\n",
    "print(f\"Labels:\\n{labels}\")\n",
    "print()\n",
    "\n",
    "# Store raw line in the dataset\n",
    "for line in lines:\n",
    "   if not line.isspace():\n",
    "      # Store sample data after removing newline characters and splitting\n",
    "      raw_dataset.append(line.strip().split(\",\"))\n",
    "\n",
    "print(\"Raw dataset:\")\n",
    "for sample in raw_dataset:\n",
    "  print(sample)\n",
    "print()\n",
    "\n",
    "# Function for detecting float typed values\n",
    "def is_float(string) -> bool:\n",
    "  try:\n",
    "    # If the value is integer typed, casting won't throw exception\n",
    "    int(string)\n",
    "    return False\n",
    "  except:\n",
    "    # The value is float typed, casting threw exception\n",
    "    return True\n",
    "\n",
    "# Process the raw data by type casting\n",
    "for row in range(0, len(raw_dataset)):\n",
    "  instance = []\n",
    "  for col in range(0, len(labels)):\n",
    "    value = raw_dataset[row][col]\n",
    "    if is_float(value):\n",
    "      instance.append(float(value))\n",
    "    else:\n",
    "      instance.append(int(value))\n",
    "  processed_dataset.append(instance)\n",
    "\n",
    "print(\"Processed dataset:\")\n",
    "for sample in processed_dataset:\n",
    "  print(sample)\n",
    "print()\n",
    "\n",
    "# Create lists for each sample for their distance changes\n",
    "for row in processed_dataset:\n",
    "   distance_changes.append([0])\n",
    "\n",
    "# Choose randomly k centroids\n",
    "centroid_indices = []\n",
    "temp_k = k\n",
    "while temp_k > 0:   \n",
    "  index = int(random() * (10**len(processed_dataset)) % len(processed_dataset))\n",
    "  if index not in centroid_indices:\n",
    "    centroid_indices.append(index)\n",
    "    temp_k -= 1\n",
    "\n",
    "# Store the centroids in dictionary\n",
    "for index in centroid_indices:\n",
    "   centroids[len(centroids.keys())+1] = processed_dataset[index]\n",
    "\n",
    "print(\"Centroids:\")\n",
    "for centroid in centroids.items():\n",
    "  print(centroid)\n",
    "print()\n",
    "\n",
    "# Initialize dictionary for each centroid for average calculation\n",
    "for centroid in centroids.keys():\n",
    "  group_averages[centroid] = {}\n",
    "  for col in range(0, len(processed_dataset[0])):\n",
    "    group_averages[centroid][col] = {\n",
    "      'sum':0,\n",
    "      'total':0,\n",
    "      'avg':0\n",
    "    }\n",
    "\n",
    "# Function of euclidean distance\n",
    "def calculate_euclidean_distance(vector_p, vector_q):\n",
    "  if len(vector_p) == len(vector_q):\n",
    "     d = 0\n",
    "     for i in range(0, len(vector_p)):\n",
    "       d += (vector_p[i] - vector_q[i])*(vector_p[i] - vector_q[i])\n",
    "     return math.sqrt(d)\n",
    "  return None\n",
    "\n",
    "# Function to update the centroids\n",
    "def update_centroids():\n",
    "  # Calculate the column-group based averages\n",
    "  for row in range(0, len(processed_dataset)):\n",
    "    # Sample data\n",
    "    sample = processed_dataset[row]\n",
    "    # Current centroid of the sample\n",
    "    current_centroid = distance_changes[row][-1]\n",
    "\n",
    "    # Go through each attribute\n",
    "    for col in range(0, len(sample)):\n",
    "      # Attribute of the sample\n",
    "      attribute = sample[col]\n",
    "      for centroid in centroids.keys():\n",
    "        # Sum attributes among same group\n",
    "        if centroid == current_centroid:\n",
    "          values = group_averages.get(centroid).get(col)\n",
    "          values['sum'] += attribute\n",
    "          values['total'] += 1\n",
    "          values['avg'] = values.get('sum') / values.get('total')\n",
    "  \n",
    "  # Update the centroid with calculated averages\n",
    "  for col in range(0, len(processed_dataset[0])):\n",
    "    for row in range(0, len(processed_dataset)):\n",
    "      # Current centroid of the sample\n",
    "      current_centroid = distance_changes[row][-1]\n",
    "      for centroid in centroids.keys():\n",
    "        if centroid == current_centroid:\n",
    "          means = centroids[centroid].copy()\n",
    "          # Insert method inserts the value before the specified index\n",
    "          means.insert(col, group_averages[centroid][col]['avg'])\n",
    "          # Combine list by excluding the value previously resided at the index\n",
    "          means = means[:col+1] + means[col+2:]\n",
    "          centroids[centroid] = means\n",
    "\n",
    "while group_changes.count(True) != 0:\n",
    "  # Reset the list\n",
    "  group_changes = []\n",
    "  \n",
    "  # Calculate the distances\n",
    "  for index in range(0, len(processed_dataset)):\n",
    "    # Sample data\n",
    "    sample = processed_dataset[index]\n",
    "    # Current centroid group\n",
    "    current_centroid = distance_changes[index][-1]\n",
    "    # Initialize list to store distances between the sample and each centroid\n",
    "    distances = []\n",
    "\n",
    "    # Calculate the distance with euclidean distance formula\n",
    "    for centroid in centroids.values():\n",
    "      d = calculate_euclidean_distance(sample, centroid)\n",
    "      distances.append(d)\n",
    "    # Check whether there is one min result\n",
    "    if distances.count(min(distances)) == 1:\n",
    "      # New centroid\n",
    "      new_centroid = distances.index(min(distances))+1\n",
    "      # Check whether the new centroid is same as the current one\n",
    "      if new_centroid == current_centroid:\n",
    "        # Preserve current group\n",
    "        distance_changes[index].append(current_centroid)\n",
    "        # No centroid change\n",
    "        group_changes.append(False)\n",
    "      else:\n",
    "        distance_changes[index].append(new_centroid)\n",
    "        group_changes.append(True)\n",
    "    # There is multiple equal results\n",
    "    else:\n",
    "      # Store their indices\n",
    "      indices = []\n",
    "\n",
    "      for i in range(0, len(distances)):\n",
    "        if min(distances) == distances[i]:\n",
    "            # The indices of centroids start by 1 not 0\n",
    "            indices.append(i+1)\n",
    "      \n",
    "      # Check whether the current centroid is in the list\n",
    "      if current_centroid in indices:\n",
    "        # Preserve current group\n",
    "        distance_changes[index].append(current_centroid)\n",
    "        # No centroid change\n",
    "        group_changes.append(False)\n",
    "      # Update new centroid\n",
    "      else:\n",
    "        # New centroid\n",
    "        new_centroid = distances.index(min(distances))+1\n",
    "        distance_changes[index].append(new_centroid)\n",
    "        group_changes.append(True)\n",
    "  \n",
    "  # Update the centroids for the next iteration\n",
    "  if group_changes.count(True) != 0:\n",
    "    update_centroids()\n",
    "\n",
    "print(f'Group changes:\\n{group_changes}')\n",
    "print()\n",
    "\n",
    "print(\"Group averages:\")\n",
    "for group, values in group_averages.items():\n",
    "  for col, means in values.items():\n",
    "    print(f\"Group:\\t{group}\\tColumn:\\t{col}\\tMeans:\\t{means}\")\n",
    "print()\n",
    "\n",
    "print(\"Distance changes:\")\n",
    "for dc in distance_changes:\n",
    "  print(dc)\n",
    "print()\n",
    "\n",
    "# Append the class to labels\n",
    "labels.append('Class')\n",
    "\n",
    "# Combine the class value with the dataset\n",
    "for row in range(0, len(processed_dataset)):\n",
    "  sample = processed_dataset[row].copy()\n",
    "  sample.append(distance_changes[row][-1])\n",
    "  clustered_dataset.append(sample)\n",
    "\n",
    "print(\"Dataset after clustering:\")\n",
    "for sample in clustered_dataset:\n",
    "  print(sample)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
