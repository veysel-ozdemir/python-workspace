{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "# Naive Bayes Classification Algorithm\n",
    "\n",
    "# ! Caution: Assumed that the dataset has no missing value.\n",
    "\n",
    "# ? How the algorithm works ?\n",
    "# Naive Bayes is a probabilistic machine learning algorithm based on Bayes' Theorem that is widely used for classification tasks.\n",
    "# P(H\\X) = P(X\\H) * P(H)/P(X) where,\n",
    "# P(H\\X): Posterior probability of Hypothesis (Class)\n",
    "# P(X\\H): Posterior probability of Input X (Features)\n",
    "# P(X): Probability of Input X (Class)\n",
    "# P(H): Probability of Hypothesis (Features)\n",
    "# \n",
    "# Steps of the algorithm:\n",
    "# 1. Data Preparation\n",
    "# 2. Calculate Class Probabilities (Prior Probabilities)\n",
    "#    ├── Determine the total number of training examples\n",
    "#    ├── Count the number of examples in each class\n",
    "#    └── Calculate the probability of each class using the formula:\n",
    "#        P(Class) = (Number of examples in the class) / (Total number of examples)\n",
    "# 3. Calculate Conditional Probabilities\n",
    "#    └── For each feature and each class, calculate the probability of the feature given the class\n",
    "# 4. Prediction for a New Instance\n",
    "#    └── For the new data point, calculate the probability for each class:\n",
    "#        Use Bayes' Theorem: P(Class|Features) = (P(Features|Class) * P(Class)) / P(Features)\n",
    "# 5. Classification Decision\n",
    "#    ├── Compare the calculated probabilities for each class\n",
    "#    ├── Select the class with the highest probability\n",
    "#    └── This becomes the predicted class for the new instance\n",
    "\n",
    "# The input data\n",
    "input_data = [1,2,0,'Small']\n",
    "\n",
    "# Initialize list for the raw dataset\n",
    "raw_dataset = []\n",
    "\n",
    "# Initialize list for the labels of dataset\n",
    "labels = []\n",
    "\n",
    "# Initialize list for the processed dataset\n",
    "processed_dataset = []\n",
    "\n",
    "# Determine the file path of dataset\n",
    "file_path = '../Custom Datasets/naive-bayes-test.csv'\n",
    "\n",
    "# Read all lines of the file\n",
    "with open(file_path, 'r') as file:\n",
    "  lines = file.readlines()\n",
    "\n",
    "# Get the line where the labels reside\n",
    "for line_number in range(0, len(lines)):\n",
    "    if not lines[line_number].isspace():\n",
    "        # Store the labels\n",
    "        labels = lines.pop(line_number).strip().split(',')\n",
    "        break\n",
    "\n",
    "print(f\"Labels:\\n{labels}\")\n",
    "print()\n",
    "\n",
    "# Store raw line in the dataset\n",
    "for line in lines:\n",
    "   if not line.isspace():\n",
    "      # Store sample data after removing newline characters and splitting\n",
    "      raw_dataset.append(line.strip().split(\",\"))\n",
    "\n",
    "print(\"Raw dataset:\")\n",
    "for sample in raw_dataset:\n",
    "  print(sample)\n",
    "print()\n",
    "\n",
    "# Function for detecting float typed values\n",
    "def is_float(string) -> bool:\n",
    "  try:\n",
    "    # If the value is integer typed, casting won't throw exception\n",
    "    int(string)\n",
    "    return False\n",
    "  except:\n",
    "    # The value is float typed, casting threw exception\n",
    "    return True\n",
    "\n",
    "# Control whether the value is numeric\n",
    "def is_numeric(value) -> bool:\n",
    "    try:\n",
    "        # Try to cast\n",
    "        float(value)\n",
    "        # The value is either float or integer\n",
    "        return True\n",
    "    except:\n",
    "        # The values is not numeric\n",
    "        return False\n",
    "\n",
    "# Process the raw data by type casting\n",
    "for row in range(0, len(raw_dataset)):\n",
    "  instance = []\n",
    "  for col in range(0, len(labels)):\n",
    "    value = raw_dataset[row][col]\n",
    "    if is_numeric(value):\n",
    "      if is_float(value):\n",
    "        instance.append(float(value))\n",
    "      else:\n",
    "        instance.append(int(value))\n",
    "    else:\n",
    "        instance.append(value)\n",
    "  processed_dataset.append(instance)\n",
    "\n",
    "print(\"Processed dataset:\")\n",
    "for sample in processed_dataset:\n",
    "  print(sample)\n",
    "print()\n",
    "\n",
    "# Count the samples of classes\n",
    "# Key: class label, Value: class count\n",
    "class_counts = dict()\n",
    "for sample in processed_dataset:\n",
    "  cl = sample[-1:].pop()\n",
    "  if class_counts.get(cl) is not None:\n",
    "    class_counts[cl] += 1\n",
    "  else:\n",
    "    class_counts[cl] = 1\n",
    "\n",
    "print(\"Class counts:\")\n",
    "for cl in class_counts.keys():\n",
    "   print(f\"{cl}:\\t{class_counts.get(cl)}\")\n",
    "print()\n",
    "\n",
    "# Calculate the ratio of each class\n",
    "# Key: Class label, Value: Ratio\n",
    "class_ratios = dict()\n",
    "for cl in class_counts.keys():\n",
    "   if class_ratios.get(cl) is not None:\n",
    "      class_ratios[cl] = round(class_counts.get(cl)/len(processed_dataset), ndigits=2)\n",
    "   else:\n",
    "      class_ratios[cl] = round(class_counts.get(cl)/len(processed_dataset), ndigits=2)\n",
    "\n",
    "print(\"Class ratios:\")\n",
    "for cl in class_ratios.keys():\n",
    "   print(f\"{cl}:\\t{class_ratios.get(cl)}\")\n",
    "print()\n",
    "\n",
    "# Count the input features per classes\n",
    "# Key: feature value, Value: dict of class labels and their inclusion counts\n",
    "features_counts = dict()\n",
    "for col in range(0, len(labels)-1): # Go through features except the class\n",
    "   for row in range(0, len(processed_dataset)):\n",
    "      feat = processed_dataset[row][col]\n",
    "      cl = processed_dataset[row][-1]\n",
    "      \n",
    "      # If the feature matches with input feature\n",
    "      if feat == input_data[col]:\n",
    "        \n",
    "        # Increment the count\n",
    "        if features_counts.get(feat) is not None:\n",
    "          if features_counts[feat].get(cl) is not None:\n",
    "            features_counts[feat][cl] += 1\n",
    "          else:\n",
    "            features_counts[feat][cl] = 1\n",
    "        else:\n",
    "          features_counts[feat] = {cl:1}\n",
    "\n",
    "print(\"Input feature counts:\")\n",
    "for feat in features_counts.keys():\n",
    "   print(f\"{feat}:\\t{features_counts.get(feat)}\")\n",
    "print()\n",
    "\n",
    "# Calculate the probabilities of the features on each classes\n",
    "# Key: Feature, Value: dict of class labels and their probabilities\n",
    "feature_probs = dict()\n",
    "for feat,feat_class_counts in features_counts.items():\n",
    "   total_feat_count = sum(feat_class_counts.values())\n",
    "   for cl,cl_count in feat_class_counts.items():\n",
    "    if feature_probs.get(feat) is not None:\n",
    "      feature_probs[feat][cl] = round(cl_count/total_feat_count, ndigits=2)\n",
    "    else:\n",
    "      feature_probs[feat] = {cl:round(cl_count/total_feat_count, ndigits=2)}\n",
    "      \n",
    "print(\"Input feature probabilities:\")\n",
    "for feat in feature_probs.keys():\n",
    "   print(f\"{feat}:\\t{feature_probs.get(feat)}\")\n",
    "print()\n",
    "\n",
    "# Calculate class probabilities of each features\n",
    "# Key: class label, Value: calculated probability\n",
    "class_probs = dict()\n",
    "for feat,feat_prob in feature_probs.items():\n",
    "  for cl,prob in feat_prob.items():\n",
    "    if class_probs.get(cl) is not None:\n",
    "        class_probs[cl] = round(class_probs.get(cl)*prob, ndigits=3)\n",
    "    else:\n",
    "        class_probs[cl] = prob\n",
    "\n",
    "print(\"Posterior probability of Features (P(X\\\\H)):\")\n",
    "for cl in class_probs.keys():\n",
    "   print(f\"{cl}:\\t{class_probs.get(cl)}\")\n",
    "print()\n",
    "\n",
    "# Calculate the probabilities of each classes\n",
    "# Key: class label, Value: class posterior probability\n",
    "post_class_prob = dict()\n",
    "for cl,prob in class_probs.items():\n",
    "   if post_class_prob.get(cl) is not None:\n",
    "       post_class_prob[cl] = round(class_probs.get(cl)*class_ratios.get(cl), ndigits=3)\n",
    "   else:\n",
    "       post_class_prob[cl] = round(class_probs.get(cl)*class_ratios.get(cl), ndigits=3)\n",
    "\n",
    "print(\"Posterior probability of Classes (P(H\\\\X)):\")\n",
    "for cl in post_class_prob.keys():\n",
    "   print(f\"{cl}:\\t{post_class_prob.get(cl)}\")\n",
    "print()\n",
    "\n",
    "# Get the key of specified unique value of the dictionary\n",
    "def get_key_by_value(dict, value):\n",
    "    for key, val in dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "# Assign the class with highest probability to the input\n",
    "input_data.append(get_key_by_value(class_probs, max(class_probs.values())))\n",
    "\n",
    "print(f\"Classified input data:\\n{input_data}\\n\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
