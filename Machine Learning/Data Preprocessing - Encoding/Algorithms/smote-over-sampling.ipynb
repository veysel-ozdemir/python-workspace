{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "['A1', 'A2', 'Class']\n",
      "\n",
      "Raw dataset:\n",
      "['4', '15', 'X']\n",
      "['5', '14', 'X']\n",
      "['6', '13', 'X']\n",
      "['5.6', '12', 'X']\n",
      "['15', '3', 'Y']\n",
      "['13', '2', 'Y']\n",
      "['16', '4', 'Y']\n",
      "['14', '3.5', 'Y']\n",
      "['15', '2.7', 'Y']\n",
      "['14.5', '3.6', 'Y']\n",
      "['16.5', '4.3', 'Y']\n",
      "['17', '3.2', 'Y']\n",
      "\n",
      "Processed dataset:\n",
      "[4, 15, 'X']\n",
      "[5, 14, 'X']\n",
      "[6, 13, 'X']\n",
      "[5.6, 12, 'X']\n",
      "[15, 3, 'Y']\n",
      "[13, 2, 'Y']\n",
      "[16, 4, 'Y']\n",
      "[14, 3.5, 'Y']\n",
      "[15, 2.7, 'Y']\n",
      "[14.5, 3.6, 'Y']\n",
      "[16.5, 4.3, 'Y']\n",
      "[17, 3.2, 'Y']\n",
      "\n",
      "Class counts:\n",
      "X:\t4\n",
      "Y:\t8\n",
      "\n",
      "Percentage value: 100.0\n",
      "New sample count: 4\n",
      "\n",
      "Minority class:\n",
      "[4, 15, 'X']\n",
      "[5, 14, 'X']\n",
      "[6, 13, 'X']\n",
      "[5.6, 12, 'X']\n",
      "\n",
      "Majority class:\n",
      "[15, 3, 'Y']\n",
      "[13, 2, 'Y']\n",
      "[16, 4, 'Y']\n",
      "[14, 3.5, 'Y']\n",
      "[15, 2.7, 'Y']\n",
      "[14.5, 3.6, 'Y']\n",
      "[16.5, 4.3, 'Y']\n",
      "[17, 3.2, 'Y']\n",
      "\n",
      "Min-Max values of minority class atrributes:\n",
      "0. Attribute:\tMin:4\tMax:6\n",
      "1. Attribute:\tMin:12\tMax:15\n",
      "\n",
      "Minority class after over-sampling:\n",
      "[4, 15, 'X']\n",
      "[5, 14, 'X']\n",
      "[6, 13, 'X']\n",
      "[5.6, 12, 'X']\n",
      "[5.96, 14.98, 'X']\n",
      "[5.37, 12.47, 'X']\n",
      "[5.82, 12.08, 'X']\n",
      "[4.73, 14.39, 'X']\n",
      "\n",
      "Dataset after over-sampling:\n",
      "[4, 15, 'X']\n",
      "[5, 14, 'X']\n",
      "[6, 13, 'X']\n",
      "[5.6, 12, 'X']\n",
      "[5.96, 14.98, 'X']\n",
      "[5.37, 12.47, 'X']\n",
      "[5.82, 12.08, 'X']\n",
      "[4.73, 14.39, 'X']\n",
      "[15, 3, 'Y']\n",
      "[13, 2, 'Y']\n",
      "[16, 4, 'Y']\n",
      "[14, 3.5, 'Y']\n",
      "[15, 2.7, 'Y']\n",
      "[14.5, 3.6, 'Y']\n",
      "[16.5, 4.3, 'Y']\n",
      "[17, 3.2, 'Y']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Minority Over-sampling TEchnique - SMOTE Algorithm\n",
    "\n",
    "# The SMOTE algorithm can be described as follows:\n",
    "# 1. Making random choices\n",
    "#   - Take difference between a sample (could be chosen randomly) and its k nearest neighbour,\n",
    "#     where k is user-defined number.\n",
    "#   - Choose randomly one sample among the k nearest neighbors.\n",
    "#   - Multiply the difference by a random number between 0 and 1.\n",
    "#   - Add this difference to the sample to generate a new synthetic example in feature space.\n",
    "#   - Continue on with next nearest neighbour up to user-defined number, basically,\n",
    "#     up to the number of new samples to be generated.\n",
    "#\n",
    "# 2. Taking the nearest neighbor\n",
    "#   - Take the difference between the feature vector (sample) under consideration and \n",
    "#     its nearest neighbor.\n",
    "#   - Multiply this difference by a random number between 0 and 1.\n",
    "#   - Add it to the feature vector under consideration.\n",
    "#   - Perform these steps until the required new samples are generated.\n",
    "#     (The formulas to find the required samples are given below.)\n",
    "\n",
    "# The formulas used in my modified SMOTE algorithm are as follows:\n",
    "# Imbalance rate = (Minority class samples / Majority class samples) * 100\n",
    "# Percentage value = [(Majority class samples / Minority class samples) - 1] * 100\n",
    "# New samples to be generated = [(Percentage value) * |Minority class samples|] / 100\n",
    "\n",
    "# ? How my algorithm works ?\n",
    "# - Calculate minimum and maximum values for each attribute (column) of the minority class\n",
    "# - Attribute of the new synthetic example = random(0-1) * (max-min) + min\n",
    "# - Continue this until the required samples are generated\n",
    "\n",
    "# ! Caution: Assumed that the dataset has no missing value and consists of numeric values only,\n",
    "# !          and the imbalanced dataset evaluated according one minority class.\n",
    "\n",
    "from random import random\n",
    "\n",
    "# Initialize list for the processed dataset\n",
    "processed_dataset = []\n",
    "\n",
    "# Initialize list for the dataset after over-sampling\n",
    "over_sampled_dataset = []\n",
    "\n",
    "# Initialize list for the raw dataset\n",
    "raw_dataset = []\n",
    "\n",
    "# Initialize list for the labels of dataset\n",
    "labels = []\n",
    "\n",
    "# Initialize dictionary for class count\n",
    "# Key: class label\n",
    "# Value: count\n",
    "class_count = dict()\n",
    "\n",
    "# Initialize list for the minority class samples\n",
    "minority_class = []\n",
    "\n",
    "# Initialize list for the majority class samples\n",
    "majority_class = []\n",
    "\n",
    "# Initialize dictionary for min-max values of each minority class attributes\n",
    "# Keys: index of attribute (column index)\n",
    "# Values: dictionary with 'min' and 'max' keys\n",
    "min_max_values = dict()\n",
    "\n",
    "# Determine the file path of dataset\n",
    "file_path = '../Custom Datasets/imbalanced-test.csv'\n",
    "\n",
    "# Read all lines of the file\n",
    "with open(file_path, 'r') as file:\n",
    "  lines = file.readlines()\n",
    "\n",
    "# Get the line where the labels reside\n",
    "for line_number in range(0, len(lines)):\n",
    "    if not lines[line_number].isspace():\n",
    "        # Store the labels\n",
    "        labels = lines.pop(line_number).strip().split(',')\n",
    "        break\n",
    "\n",
    "print(f\"Labels:\\n{labels}\")\n",
    "print()\n",
    "\n",
    "# Store raw line in the dataset\n",
    "for line in lines:\n",
    "   if not line.isspace():\n",
    "      # Store sample data after removing newline characters and splitting\n",
    "      raw_dataset.append(line.strip().split(\",\"))\n",
    "\n",
    "print(\"Raw dataset:\")\n",
    "for sample in raw_dataset:\n",
    "  print(sample)\n",
    "print()\n",
    "\n",
    "# Function for detecting numeric typed values\n",
    "def is_numeric(value) -> bool:\n",
    "    try:\n",
    "        # Try to cast\n",
    "        float(value)\n",
    "        # The value is either float or integer\n",
    "        return True\n",
    "    except:\n",
    "        # The values is not numeric\n",
    "        return False\n",
    "\n",
    "# Function for detecting float typed values\n",
    "def is_float(string) -> bool:\n",
    "  try:\n",
    "    # If the value is integer typed, casting won't throw exception\n",
    "    int(string)\n",
    "    return False\n",
    "  except:\n",
    "    # The value is float typed, casting threw exception\n",
    "    return True\n",
    "\n",
    "# Process the raw data by type casting\n",
    "for row in range(0, len(raw_dataset)):\n",
    "  instance = []\n",
    "  for col in range(0, len(labels)):\n",
    "    value = raw_dataset[row][col]\n",
    "    if not is_numeric(value):\n",
    "      instance.append(value)\n",
    "    elif is_float(value):\n",
    "      instance.append(float(value))\n",
    "    else:\n",
    "      instance.append(int(value))\n",
    "  processed_dataset.append(instance)\n",
    "\n",
    "print(\"Processed dataset:\")\n",
    "for sample in processed_dataset:\n",
    "  print(sample)\n",
    "print()\n",
    "\n",
    "# Count the samples of each class\n",
    "for sample in processed_dataset:\n",
    "   for cl in sample[-1]:\n",
    "     if class_count.get(cl) is not None:\n",
    "        class_count[cl] += 1\n",
    "     else:\n",
    "        class_count[cl] = 1\n",
    "\n",
    "print(\"Class counts:\")\n",
    "for cl in class_count.keys():\n",
    "   print(f\"{cl}:\\t{class_count.get(cl)}\")\n",
    "print()\n",
    "\n",
    "# Get the key of specified unique value of the dictionary\n",
    "def get_key_by_value(dict, value):\n",
    "    for key, val in dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "# Get sample counts of each class\n",
    "majority_class_samples = max(class_count.values())\n",
    "minority_class_samples = min(class_count.values())\n",
    "\n",
    "# Get labels of each class\n",
    "majority_class_label = get_key_by_value(class_count, majority_class_samples)\n",
    "minority_class_label = get_key_by_value(class_count, minority_class_samples)\n",
    "\n",
    "# Percentage value = [(Majority class samples / Minority class samples) - 1] * 100\n",
    "percentage_value = ((majority_class_samples / minority_class_samples) - 1) * 100\n",
    "\n",
    "# New samples to be generated = [(Percentage value) * |Minority class samples|] / 100\n",
    "new_sample_count = int((percentage_value * minority_class_samples) / 100)\n",
    "\n",
    "print(f\"Percentage value: {percentage_value}\\nNew sample count: {new_sample_count}\\n\")\n",
    "\n",
    "# Separate minority and majority classes\n",
    "for sample in processed_dataset:\n",
    "  if sample[labels.index('Class')] == minority_class_label:\n",
    "    minority_class.append(sample)\n",
    "  elif sample[labels.index('Class')] == majority_class_label:\n",
    "    majority_class.append(sample)\n",
    "\n",
    "print(\"Minority class:\")\n",
    "for min_sample in minority_class:\n",
    "   print(min_sample)\n",
    "print()\n",
    "\n",
    "print(\"Majority class:\")\n",
    "for max_sample in majority_class:\n",
    "   print(max_sample)\n",
    "print()\n",
    "\n",
    "# Function to calculate min-max values of each attribute of the dataset\n",
    "def update_minority_min_max(dataset):\n",
    "  for row in range(0, len(dataset)):\n",
    "    sample = dataset[row]\n",
    "    for col in range(0, len(sample)):\n",
    "        if col == labels.index('Class'):\n",
    "          continue\n",
    "        else:\n",
    "          attribute = sample[col]\n",
    "          # Initialize dictionary if not exists\n",
    "          if min_max_values.get(col) is None:\n",
    "            min_max_values[col] = {\n",
    "                'min': attribute,\n",
    "                'max': attribute\n",
    "            }\n",
    "          else:\n",
    "            if min_max_values[col]['min'] > attribute:\n",
    "                min_max_values[col]['min'] = attribute\n",
    "            elif min_max_values[col]['max'] < attribute:\n",
    "                min_max_values[col]['max'] = attribute\n",
    "\n",
    "# Initialize min-max values of each attribute\n",
    "update_minority_min_max(minority_class)\n",
    "\n",
    "print(\"Min-Max values of minority class atrributes:\")\n",
    "for attr in range(0, len(labels[:-1])):\n",
    "   print(f\"{attr}. Attribute:\\tMin:{min_max_values[attr]['min']}\\tMax:{min_max_values[attr]['max']}\")\n",
    "print()\n",
    "\n",
    "# Function to generate attribute for new synthetic sample\n",
    "def generate_synthetic_attribute(attribute_index):\n",
    "   min_value = min_max_values[attribute_index]['min']\n",
    "   max_value = min_max_values[attribute_index]['max']\n",
    "   new_synthetic_sample = (max_value - min_value) * random() + min_value\n",
    "   return round(new_synthetic_sample, 2)\n",
    "\n",
    "for row in range(0, len(minority_class)):\n",
    "  if new_sample_count == 0:\n",
    "    break\n",
    "  else:\n",
    "    new_synthetic_sample = []\n",
    "    for col in range(0, len(labels)):\n",
    "      if col == labels.index('Class'):\n",
    "        continue\n",
    "      else:   \n",
    "        new_attribute = generate_synthetic_attribute(col)\n",
    "        new_synthetic_sample.append(new_attribute)\n",
    "    new_synthetic_sample.append(minority_class_label)\n",
    "    minority_class.append(new_synthetic_sample)\n",
    "    update_minority_min_max(minority_class)\n",
    "    new_sample_count -= 1\n",
    "\n",
    "print(\"Minority class after over-sampling:\")\n",
    "for sample in minority_class:\n",
    "   print(sample)\n",
    "print()\n",
    "\n",
    "# Combine the classes\n",
    "over_sampled_dataset = minority_class + majority_class\n",
    "\n",
    "print(\"Dataset after over-sampling:\")\n",
    "for sample in over_sampled_dataset:\n",
    "   print(sample)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
